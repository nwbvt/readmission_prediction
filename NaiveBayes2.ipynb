{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier on MIMICIII medical Notes\n",
    "    By Binghui Zhang (bzhang62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import re\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load training and testing datasets. Label response categories according to readmission.\n",
    "    If readmitted within 30 days label as 1, else 0 (not readmitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"Data/train.csv\",keep_default_na=False)\n",
    "data_test = pd.read_csv(\"Data/test.csv\",keep_default_na=False)\n",
    "train_set = data_train[\"TEXT\"]\n",
    "train_y = data_train[\"DAYS_TO_READMIT\"]\n",
    "test_set = data_test[\"TEXT\"]\n",
    "test_y = data_test[\"DAYS_TO_READMIT\"]\n",
    "for i in range(len(train_y)):\n",
    "    train_set[i] = re.sub(r\"[^a-z0-9]\",\" \",train_set[i].lower())\n",
    "    train_y[i] = int(train_y[i] or 0)\n",
    "    if train_y[i] <= 30 : train_y[i]=1\n",
    "    else : train_y[i] = 0\n",
    "for i in range(len(test_y)):\n",
    "    test_set[i] = re.sub(r\"[^a-z0-9]\",\" \",test_set[i].lower())\n",
    "    test_y[i] = int(test_y[i] or 0)\n",
    "    if test_y[i] <= 30 : test_y[i]=1\n",
    "    else : test_y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype('int')\n",
    "test_y = test_y.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create tokenizer and tokenize vocab into integers. Features reflect whether a word was used in the note or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000,oov_token=0)\n",
    "tokenizer.fit_on_texts(train_set)\n",
    "tokenizer.fit_on_texts(test_set)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 238470\n",
      "admission: 55\n",
      "date: 57\n",
      "admission date      \n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_matrix(train_set, mode='binary')\n",
    "X_test = tokenizer.texts_to_matrix(test_set, mode='binary')\n",
    "\n",
    "print('vocab size:', vocab_size)\n",
    "for word in ['admission', 'date']:\n",
    "    print('{}: {}'.format(word, tokenizer.word_index[word]))\n",
    "print(test_set[2][0:20])\n",
    "print(X_test[2][55],X_test[2][57])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train Naive Bayes Classifier with different priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB(class_prior=[0.8, 0.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CategoricalNB(class_prior=[0.8,0.2])\n",
    "clf.fit(X_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722638278395505\n",
      "0.6470642370697589\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train,train_y))\n",
    "print(clf.score(X_test,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB(class_prior=[0.5, 0.5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = CategoricalNB(class_prior=[0.5,0.5])\n",
    "clf2.fit(X_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7229776118814069\n",
      "0.6474323578133628\n"
     ]
    }
   ],
   "source": [
    "print(clf2.score(X_train,train_y))\n",
    "print(clf2.score(X_test,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train two Gaussian Naive Bayes model with different priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=[0.8, 0.2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB(priors=[0.8,0.2])\n",
    "gnb.fit(X_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7460128315406529\n",
      "0.676513896558071\n"
     ]
    }
   ],
   "source": [
    "print(gnb.score(X_train,train_y))\n",
    "print(gnb.score(X_test,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=[0.5, 0.5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb2 = GaussianNB(priors=[0.5,0.5])\n",
    "gnb2.fit(X_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7460365059699019\n",
      "0.676513896558071\n"
     ]
    }
   ],
   "source": [
    "print(gnb2.score(X_train,train_y))\n",
    "print(gnb2.score(X_test,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Display precision scores of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions Scores:\n",
      "    Naive Bayes Classifier with informed prior: 0.96\n",
      "    Naive Bayes Classifier with flat prior: 0.96\n",
      "    Gaussian Naive Bayes Classifier with informed prior: 0.947\n",
      "    Gaussian Naive Bayes Classifier with flat prior: 0.947\n"
     ]
    }
   ],
   "source": [
    "print('Precisions Scores:')\n",
    "print('    Naive Bayes Classifier with informed prior:',round(average_precision_score(test_y,clf.predict_proba(X_test)[:,1]),3))\n",
    "print('    Naive Bayes Classifier with flat prior:', round(average_precision_score(test_y, clf2.predict_proba(X_test)[:,1]),3))\n",
    "print('    Gaussian Naive Bayes Classifier with informed prior:', round(average_precision_score(test_y, gnb.predict_proba(X_test)[:,1]),3))\n",
    "print('    Gaussian Naive Bayes Classifier with flat prior:', round(average_precision_score(test_y, gnb2.predict_proba(X_test)[:,1]),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.72133528e-118, 8.94651515e-090, 4.37404031e-263, 3.78201287e-166,\n",
       "       8.80862544e-161, 1.00000000e+000, 8.17366011e-011, 1.76031340e-148,\n",
       "       1.00000000e+000, 1.00000000e+000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[0:10])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "5    1\n",
       "6    1\n",
       "7    0\n",
       "8    1\n",
       "9    1\n",
       "Name: DAYS_TO_READMIT, dtype: int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
